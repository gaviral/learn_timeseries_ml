{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy and download a model\n",
    "!pip install -U spacy spacy-lookups-data\n",
    "!python -m spacy download en_core_web_sm  # smaller model\n",
    "# !python -m spacy download en_core_web_trf  # larger, more accurate transformer-based model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -U spacy spacy-lookups-data\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Initialize a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the NER component to the pipeline\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add the new 'SKU' label to the NER component\n",
    "ner.add_label(\"SKU\")\n",
    "\n",
    "# Create training data with correct character offsets\n",
    "TRAIN_DATA = [\n",
    "    (\"Give me cartridge for 007-F5\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"Provide me cartridge for 008-S7\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 009-B6\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    # ... rest of your training data ...\n",
    "]\n",
    "\n",
    "# Function to check entity alignment\n",
    "def check_alignment(nlp, train_data):\n",
    "    print(\"Checking entity alignment...\")\n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        tags = offsets_to_biluo_tags(doc, annotations.get(\"entities\"))\n",
    "        if \"-\" in tags:\n",
    "            print(f\"Misaligned entities in: {text}\")\n",
    "            print(f\"Tags: {tags}\")\n",
    "\n",
    "check_alignment(nlp, TRAIN_DATA)\n",
    "\n",
    "# Training loop\n",
    "with nlp.disable_pipes(*[pipe for pipe in nlp.pipe_names if pipe != \"ner\"]):\n",
    "    optimizer = nlp.initialize()\n",
    "    for itn in range(100):\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "            nlp.update([example], drop=0.2, losses=losses)\n",
    "        if itn % 20 == 0:\n",
    "            print(f\"Iteration {itn}, Losses: {losses}\")\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(\"sku_ner_model\")\n",
    "\n",
    "# Test the model\n",
    "test_texts = [\n",
    "    \"I need parts for 016-H8\",\n",
    "    \"Give me cartridge for 007-F5\",\n",
    "    \"Need to order ABC-123\",\n",
    "    \"Replace XYZ-789\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting the model:\")\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/aviralgarg/.pyenv/versions/3.10.15/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/aviralgarg/.pyenv/versions/3.10.15/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/aviralgarg/.pyenv/versions/3.10.15/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/aviralgarg/.pyenv/versions/3.10.15/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/aviralgarg/.pyenv/versions/3.10.15/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/40/74x1l5gn1dg1_nq_z_2818hh0000gn/T/ipykernel_34671/2647102708.py\", line 4, in <module>\n",
      "    import spacy\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/thinc/types.py\", line 25, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking entity alignment...\n",
      "Misaligned entities in: Give me cartridge for 007-F5\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: Provide me cartridge for 008-S7\n",
      "Tags: ['O', 'O', 'O', '-', '-', '-', 'O']\n",
      "Misaligned entities in: I need cartridge for 009-B6\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 010-A3\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 011-C4\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 012-D2\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 013-E1\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 014-F6\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need cartridge for 015-G7\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need parts for 016-H8\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need parts for 017-I9\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: I need parts for 018-J0\n",
      "Tags: ['O', 'O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: Need to order ABC-123\n",
      "Tags: ['O', 'O', 'O', 'U-SKU']\n",
      "Misaligned entities in: Product ID: 016-H8\n",
      "Tags: ['O', 'O', 'O', '-', '-', '-']\n",
      "Misaligned entities in: Check inventory for ABC-123 and XYZ-789\n",
      "Tags: ['O', 'O', 'O', '-', 'O', '-']\n",
      "Misaligned entities in: Order placed for 007-F5\n",
      "Tags: ['O', 'O', 'O', '-', '-', '-']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Give me cartridge for 007-F5\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Provide me cartridge for 008-S7\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 009-B6\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 010-A3\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 011-C4\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 012-D2\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 013-E1\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 014-F6\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need cartridge for 015-G7\" with entities \"[(23, 29, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need parts for 016-H8\" with entities \"[(19, 25, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need parts for 017-I9\" with entities \"[(19, 25, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I need parts for 018-J0\" with entities \"[(19, 25, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Product ID: 016-H8\" with entities \"[(11, 17, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Check inventory for ABC-123 and XYZ-789\" with entities \"[(19, 26, 'SKU'), (31, 38, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Order placed for 007-F5\" with entities \"[(16, 22, 'SKU')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': np.float32(35.755764)}\n",
      "Iteration 20, Losses: {'ner': np.float32(4.2526622e-07)}\n",
      "Iteration 40, Losses: {'ner': np.float32(4.765472e-08)}\n",
      "Iteration 60, Losses: {'ner': np.float32(3.4979305e-08)}\n",
      "Iteration 80, Losses: {'ner': np.float32(1.1496209e-08)}\n",
      "\n",
      "Model saved to 'sku_ner_model'.\n",
      "\n",
      "Testing the trained model on various examples:\n",
      "\n",
      "Text: I need parts for 016-H8\n",
      "Entities found: [('016-H8', 'SKU')]\n",
      "\n",
      "Text: Give me cartridge for 007-F5\n",
      "Entities found: [('007-F5', 'SKU')]\n",
      "\n",
      "Text: Need to order ABC-123\n",
      "Entities found: [('ABC-123', 'SKU')]\n",
      "\n",
      "Text: Replace XYZ-789\n",
      "Entities found: [('XYZ-789', 'SKU')]\n",
      "\n",
      "Text: Check stock of 019-K1\n",
      "Entities found: [('019-K1', 'SKU')]\n",
      "\n",
      "Text: Product reference: 020-L2\n",
      "Entities found: [('020-L2', 'SKU')]\n",
      "\n",
      "Loading and testing the saved model:\n",
      "\n",
      "Text: I need parts for 016-H8\n",
      "Entities found: [('016-H8', 'SKU')]\n",
      "\n",
      "Text: Give me cartridge for 007-F5\n",
      "Entities found: [('007-F5', 'SKU')]\n",
      "\n",
      "Text: Need to order ABC-123\n",
      "Entities found: [('ABC-123', 'SKU')]\n",
      "\n",
      "Text: Replace XYZ-789\n",
      "Entities found: [('XYZ-789', 'SKU')]\n",
      "\n",
      "Text: Check stock of 019-K1\n",
      "Entities found: [('019-K1', 'SKU')]\n",
      "\n",
      "Text: Product reference: 020-L2\n",
      "Entities found: [('020-L2', 'SKU')]\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install -U spacy spacy-lookups-data\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Initialize a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the NER component to the pipeline\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add the new 'SKU' label to the NER component\n",
    "ner.add_label(\"SKU\")\n",
    "\n",
    "# Create training data with correct character offsets\n",
    "TRAIN_DATA = [\n",
    "    (\"Give me cartridge for 007-F5\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"Provide me cartridge for 008-S7\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 009-B6\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 010-A3\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 011-C4\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 012-D2\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 013-E1\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 014-F6\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need cartridge for 015-G7\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "    (\"I need parts for 016-H8\", {\"entities\": [(19, 25, \"SKU\")]}),\n",
    "    (\"I need parts for 017-I9\", {\"entities\": [(19, 25, \"SKU\")]}),\n",
    "    (\"I need parts for 018-J0\", {\"entities\": [(19, 25, \"SKU\")]}),\n",
    "    (\"Need to order ABC-123\", {\"entities\": [(14, 21, \"SKU\")]}),\n",
    "    (\"Replace XYZ-789 with 123-A4\", {\"entities\": [(8, 15, \"SKU\"), (21, 27, \"SKU\")]}),\n",
    "    # Additional diverse examples\n",
    "    (\"SKU 016-H8 needs replacement\", {\"entities\": [(4, 10, \"SKU\")]}),\n",
    "    (\"Product ID: 016-H8\", {\"entities\": [(11, 17, \"SKU\")]}),\n",
    "    (\"016-H8 is out of stock\", {\"entities\": [(0, 6, \"SKU\")]}),\n",
    "    (\"Check inventory for ABC-123 and XYZ-789\", {\"entities\": [(19, 26, \"SKU\"), (31, 38, \"SKU\")]}),\n",
    "    (\"Order placed for 007-F5\", {\"entities\": [(16, 22, \"SKU\")]}),\n",
    "]\n",
    "\n",
    "# Function to check entity alignment\n",
    "def check_alignment(nlp, train_data):\n",
    "    print(\"Checking entity alignment...\")\n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        tags = offsets_to_biluo_tags(doc, annotations.get(\"entities\"))\n",
    "        if \"X\" in tags or \"O\" in tags and \"B-SKU\" not in tags:\n",
    "            print(f\"Misaligned entities in: {text}\")\n",
    "            print(f\"Tags: {tags}\")\n",
    "\n",
    "check_alignment(nlp, TRAIN_DATA)\n",
    "\n",
    "# Initialize the training\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# Disable other pipes for training to speed up and avoid interference\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    # Training loop\n",
    "    for itn in range(100):\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], drop=0.2, losses=losses)\n",
    "        if itn % 20 == 0:\n",
    "            print(f\"Iteration {itn}, Losses: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"sku_ner_model\")\n",
    "print(\"\\nModel saved to 'sku_ner_model'.\")\n",
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model on various examples:\")\n",
    "TEST_TEXTS = [\n",
    "    \"I need parts for 016-H8\",\n",
    "    \"Give me cartridge for 007-F5\",\n",
    "    \"Need to order ABC-123\",\n",
    "    \"Replace XYZ-789\",\n",
    "    \"Check stock of 019-K1\",           # New SKU not in training\n",
    "    \"Product reference: 020-L2\",      # Different format\n",
    "]\n",
    "\n",
    "for text in TEST_TEXTS:\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"Entities found:\", entities)\n",
    "\n",
    "# Load and test the saved model\n",
    "print(\"\\nLoading and testing the saved model:\")\n",
    "loaded_nlp = spacy.load(\"sku_ner_model\")\n",
    "\n",
    "for text in TEST_TEXTS:\n",
    "    doc = loaded_nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"Entities found:\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I need parts for 016-H8\"\n",
    "\n",
    "# # Process the text\n",
    "# doc = nlp(text)\n",
    "\n",
    "# # Display entities\n",
    "# for ent in doc.ents:\n",
    "#     print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, install required package\n",
    "# # !pip install spacy-lookups-data\n",
    "\n",
    "# import spacy\n",
    "# from spacy.tokens import DocBin\n",
    "# from spacy.cli.train import train\n",
    "# from spacy.training import Example\n",
    "# from spacy.training import offsets_to_biluo_tags\n",
    "\n",
    "# # Create training data with corrected entity spans\n",
    "# TRAIN_DATA = [\n",
    "#     (\"Give me cartridge for 007-F5\", {\"entities\": [(23, 29, \"SKU\")]}),  # Adjusted span\n",
    "#     (\"Provide me cartridge for 008-S7\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 009-B6\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 010-A3\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 011-C4\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 012-D2\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 013-E1\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 014-F6\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need cartridge for 015-G7\", {\"entities\": [(23, 29, \"SKU\")]}),\n",
    "#     (\"I need parts for 016-H8\", {\"entities\": [(16, 22, \"SKU\")]}),\n",
    "#     (\"I need parts for 017-I9\", {\"entities\": [(16, 22, \"SKU\")]}),\n",
    "#     (\"I need parts for 018-J0\", {\"entities\": [(16, 22, \"SKU\")]}),\n",
    "#     (\"Need to order ABC-123\", {\"entities\": [(14, 21, \"SKU\")]}),\n",
    "#     (\"Replace XYZ-789 with 123-A4\", {\"entities\": [(8, 15, \"SKU\"), (21, 27, \"SKU\")]}),\n",
    "#     # Additional diverse examples\n",
    "#     (\"SKU 016-H8 needs replacement\", {\"entities\": [(4, 10, \"SKU\")]}),\n",
    "#     (\"Product ID: 016-H8\", {\"entities\": [(11, 17, \"SKU\")]}),\n",
    "#     (\"016-H8 is out of stock\", {\"entities\": [(0, 6, \"SKU\")]}),\n",
    "#     (\"Check inventory for ABC-123 and XYZ-789\", {\"entities\": [(19, 26, \"SKU\"), (31, 38, \"SKU\")]}),\n",
    "#     (\"Order placed for 007-F5\", {\"entities\": [(16, 22, \"SKU\")]})\n",
    "# ]\n",
    "\n",
    "# # Start with pre-trained model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Check entity alignment before training\n",
    "# print(\"Checking entity alignment...\")\n",
    "# for text, annotations in TRAIN_DATA:\n",
    "#     doc = nlp.make_doc(text)\n",
    "#     tags = offsets_to_biluo_tags(doc, annotations.get(\"entities\"))\n",
    "#     if \"-\" in tags:\n",
    "#         print(f\"Misaligned entities in: {text}\")\n",
    "#         print(f\"Tags: {tags}\")\n",
    "\n",
    "# # Add NER component\n",
    "# if \"ner\" not in nlp.pipe_names:\n",
    "#     ner = nlp.add_pipe(\"ner\")\n",
    "# else:\n",
    "#     ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# # Add new label\n",
    "# ner.add_label(\"SKU\")\n",
    "\n",
    "# # Disable other pipeline components during training\n",
    "# other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "# with nlp.disable_pipes(*other_pipes):\n",
    "#     # Train the model\n",
    "#     optimizer = nlp.begin_training()\n",
    "#     for itn in range(100):\n",
    "#         losses = {}\n",
    "#         for text, annotations in TRAIN_DATA:\n",
    "#             example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "#             nlp.update([example], drop=0.2, losses=losses)\n",
    "#         if itn % 20 == 0:\n",
    "#             print(f\"Losses at iteration {itn}: {losses}\")\n",
    "\n",
    "# # Save the model\n",
    "# nlp.to_disk(\"sku_ner_model\")\n",
    "\n",
    "# # Test the model\n",
    "# print(\"\\nTesting model on various examples:\")\n",
    "# test_texts = [\n",
    "#     \"I need parts for 016-H8\",\n",
    "#     \"Give me cartridge for 007-F5\",\n",
    "#     \"Need to order ABC-123\",\n",
    "#     \"Replace XYZ-789\",\n",
    "#     \"Check stock of 019-K1\",  # New SKU not in training\n",
    "#     \"Product reference: 020-L2\"  # Different format\n",
    "# ]\n",
    "\n",
    "# for test_text in test_texts:\n",
    "#     doc = nlp(test_text)\n",
    "#     print(f\"\\nText: {test_text}\")\n",
    "#     print(\"Entities found:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/ae/53/418536f5d0b87bfbe7bbd8c001983c27e9474f82723bd2e529660fd9a534/streamlit-1.40.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/aa/f3/0b6ced594e51cc95d8c1fc1640d3623770d01e4969d29c0bd09945fafefa/altair-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for cachetools<6,>=4.0 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (4.25.5)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Obtaining dependency information for pyarrow>=7.0 from https://files.pythonhosted.org/packages/30/90/893acfad917533b624a97b9e498c0e8393908508a0a72d624fe935e632bf/pyarrow-18.1.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Obtaining dependency information for toml<2,>=0.10.1 from https://files.pythonhosted.org/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Obtaining dependency information for pydeck<1,>=0.8.0b4 from https://files.pythonhosted.org/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Obtaining dependency information for narwhals>=1.14.2 from https://files.pythonhosted.org/packages/ac/e7/fe3d69098e628e81cf317e860474e5df02a5a681b031acbf2aaf192cef3f/narwhals-1.15.2-py3-none-any.whl.metadata\n",
      "  Downloading narwhals-1.15.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting numpy<3,>=1.23 (from streamlit)\n",
      "  Obtaining dependency information for numpy<3,>=1.23 from https://files.pythonhosted.org/packages/a7/94/ace0fdea5241a27d13543ee117cbc65868e82213fb31a8eb7fe9ff23f313/numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Downloading pyarrow-18.1.0-cp310-cp310-macosx_12_0_x86_64.whl (30.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.15.2-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: toml, smmap, pyarrow, numpy, narwhals, cachetools, pydeck, gitdb, gitpython, altair, streamlit\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed altair-5.5.0 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 narwhals-1.15.2 numpy-1.26.4 pyarrow-18.1.0 pydeck-0.9.1 smmap-5.0.1 streamlit-1.40.2 toml-0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:28:27.222 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.223 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-12-04 17:28:27.223 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.225 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.226 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.227 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.228 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.229 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.400 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/aviralgarg/code/stocks_3_10/.venv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-04 17:28:27.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:27.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "\n",
    "# Initialize session state for annotations\n",
    "if 'annotations' not in st.session_state:\n",
    "    st.session_state.annotations = []\n",
    "\n",
    "# Initialize session state for entity types\n",
    "if 'entity_types' not in st.session_state:\n",
    "    st.session_state.entity_types = ['SKU']\n",
    "\n",
    "st.title(\"NER Annotation Tool\")\n",
    "st.write(\"Select text and assign named entities.\")\n",
    "\n",
    "# Text input\n",
    "text = st.text_area(\"Enter Text for Annotation:\", height=200)\n",
    "\n",
    "# Container to show selected text and assign entity\n",
    "if text:\n",
    "    st.markdown(\"### Annotate Entities\")\n",
    "    st.markdown(\"Select a portion of the text below, and assign an entity type from the dropdown menu.\")\n",
    "    \n",
    "    # Display the text with a unique identifier for selection\n",
    "    st.write(text, unsafe_allow_html=True)\n",
    "    \n",
    "    # Placeholder for annotations\n",
    "    placeholder = st.empty()\n",
    "    \n",
    "    # Button to add a new entity type\n",
    "    if st.button(\"Add New Entity Type\"):\n",
    "        new_entity = st.text_input(\"Enter new entity type:\")\n",
    "        if new_entity:\n",
    "            st.session_state.entity_types.append(new_entity)\n",
    "            st.success(f\"Added new entity type: {new_entity}\")\n",
    "    \n",
    "    # Dropdown to select entity type\n",
    "    entity_type = st.selectbox(\"Select Entity Type:\", st.session_state.entity_types)\n",
    "    \n",
    "    # Button to save annotation\n",
    "    if st.button(\"Save Annotation\"):\n",
    "        # Here, you'd capture the selected text and its span\n",
    "        # For simplicity, we'll simulate with placeholders\n",
    "        # In a real scenario, you'd use JavaScript to get selected text and its indices\n",
    "        selected_text = st.text_input(\"Selected Text:\")\n",
    "        start_pos = st.number_input(\"Start Position:\", min_value=0)\n",
    "        end_pos = st.number_input(\"End Position:\", min_value=0)\n",
    "        \n",
    "        if selected_text and start_pos < end_pos:\n",
    "            annotation = {\n",
    "                \"text\": selected_text,\n",
    "                \"start\": start_pos,\n",
    "                \"end\": end_pos,\n",
    "                \"label\": entity_type\n",
    "            }\n",
    "            st.session_state.annotations.append(annotation)\n",
    "            st.success(f\"Annotated: {selected_text} as {entity_type}\")\n",
    "    \n",
    "    # Display current annotations\n",
    "    st.markdown(\"### Current Annotations\")\n",
    "    for annot in st.session_state.annotations:\n",
    "        st.write(f\"{annot['text']} --> {annot['label']} [{annot['start']}, {annot['end']}]\")\n",
    "    \n",
    "    # Save annotations to a JSON file\n",
    "    if st.button(\"Save Annotations\"):\n",
    "        with open(\"annotations.json\", \"w\") as f:\n",
    "            json.dump(st.session_state.annotations, f, indent=4)\n",
    "        st.success(\"Annotations saved to 'annotations.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement streamlit-components (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for streamlit-components\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:28:51.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-04 17:28:51.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import streamlit.components.v1 as components\n",
    "\n",
    "# Initialize session state for annotations\n",
    "if 'annotations' not in st.session_state:\n",
    "    st.session_state.annotations = []\n",
    "\n",
    "# Initialize session state for entity types\n",
    "if 'entity_types' not in st.session_state:\n",
    "    st.session_state.entity_types = ['SKU']\n",
    "\n",
    "st.title(\"NER Annotation Tool\")\n",
    "st.write(\"Select text and assign named entities.\")\n",
    "\n",
    "# Text input\n",
    "text = st.text_area(\"Enter Text for Annotation:\", height=200)\n",
    "\n",
    "if text:\n",
    "    st.markdown(\"### Annotate Entities\")\n",
    "    st.markdown(\"Select a portion of the text below, and assign an entity type from the dropdown menu.\")\n",
    "    \n",
    "    # HTML and JavaScript for text selection\n",
    "    html_code = f\"\"\"\n",
    "    <div id=\"text-container\" style=\"border:1px solid #ccc; padding:10px; border-radius:5px;\">\n",
    "        {text}\n",
    "    </div>\n",
    "    <script>\n",
    "        const textContainer = document.getElementById(\"text-container\");\n",
    "        textContainer.addEventListener(\"mouseup\", function() {{\n",
    "            const selection = window.getSelection();\n",
    "            const selectedText = selection.toString();\n",
    "            if (selectedText.length > 0) {{\n",
    "                const range = selection.getRangeAt(0);\n",
    "                const preSelectionRange = range.cloneRange();\n",
    "                preSelectionRange.selectNodeContents(textContainer);\n",
    "                preSelectionRange.setEnd(range.startContainer, range.startOffset);\n",
    "                const start = preSelectionRange.toString().length;\n",
    "                const end = start + range.toString().length;\n",
    "                // Send the data back to Streamlit\n",
    "                window.parent.postMessage({{\n",
    "                    'type': 'selection',\n",
    "                    'selected_text': selectedText,\n",
    "                    'start': start,\n",
    "                    'end': end\n",
    "                }}, '*');\n",
    "            }}\n",
    "        }});\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a placeholder for the JavaScript component\n",
    "    components.html(html_code, height=300)\n",
    "    \n",
    "    # JavaScript to Streamlit communication\n",
    "    selection = st.experimental_get_query_params().get(\"selected_text\", [None])[0]\n",
    "    start = st.experimental_get_query_params().get(\"start\", [0])[0]\n",
    "    end = st.experimental_get_query_params().get(\"end\", [0])[0]\n",
    "    \n",
    "    # Define a component to capture the JavaScript message\n",
    "    selection_data = st.empty()\n",
    "    \n",
    "    # Custom Streamlit component to handle messages\n",
    "    components_js = \"\"\"\n",
    "    <script>\n",
    "    window.addEventListener(\"message\", function(event) {\n",
    "        if (event.data && event.data.type === 'selection') {\n",
    "            const selected_text = event.data.selected_text;\n",
    "            const start = event.data.start;\n",
    "            const end = event.data.end;\n",
    "            // Send to Streamlit\n",
    "            const data = {selected_text, start, end};\n",
    "            window.parent.postMessage({ \"streamlit-message\": JSON.stringify(data) }, \"*\");\n",
    "        }\n",
    "    });\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    components.html(components_js)\n",
    "    \n",
    "    # Placeholder to display selected text\n",
    "    selected_text = st.text_input(\"Selected Text:\")\n",
    "    selected_start = st.number_input(\"Start Position:\", min_value=0, value=0)\n",
    "    selected_end = st.number_input(\"End Position:\", min_value=0, value=0)\n",
    "    \n",
    "    # Dropdown to select entity type\n",
    "    entity_type = st.selectbox(\"Select Entity Type:\", st.session_state.entity_types)\n",
    "    \n",
    "    # Button to save annotation\n",
    "    if st.button(\"Save Annotation\"):\n",
    "        if selected_text and selected_start < selected_end:\n",
    "            annotation = {\n",
    "                \"text\": selected_text,\n",
    "                \"start\": selected_start,\n",
    "                \"end\": selected_end,\n",
    "                \"label\": entity_type\n",
    "            }\n",
    "            st.session_state.annotations.append(annotation)\n",
    "            st.success(f\"Annotated: {selected_text} as {entity_type}\")\n",
    "        else:\n",
    "            st.error(\"Please select valid text and positions.\")\n",
    "    \n",
    "    # Button to add a new entity type\n",
    "    if st.button(\"Add New Entity Type\"):\n",
    "        new_entity = st.text_input(\"Enter new entity type:\")\n",
    "        if new_entity:\n",
    "            st.session_state.entity_types.append(new_entity)\n",
    "            st.success(f\"Added new entity type: {new_entity}\")\n",
    "    \n",
    "    # Display current annotations\n",
    "    st.markdown(\"### Current Annotations\")\n",
    "    for annot in st.session_state.annotations:\n",
    "        st.write(f\"{annot['text']} --> {annot['label']} [{annot['start']}, {annot['end']}]\")\n",
    "    \n",
    "    # Save annotations to a JSON file\n",
    "    if st.button(\"Save Annotations\"):\n",
    "        with open(\"annotations.json\", \"w\") as f:\n",
    "            json.dump(st.session_state.annotations, f, indent=4)\n",
    "        st.success(\"Annotations saved to 'annotations.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      👋 \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "      If you’d like to receive helpful onboarding emails, news, offers, promotions,\n",
      "      and the occasional swag, please enter your email address below. Otherwise,\n",
      "      leave this field blank.\n",
      "\n",
      "      \u001b[34mEmail: \u001b[0m ^C\n",
      "2024-12-04 17:33:08.449 \n"
     ]
    }
   ],
   "source": [
    "# save the last cell into a file called ner_annotation_app.py\n",
    "# then go to terminal and \n",
    "\n",
    "!streamlit run ner_annotation_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
